{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Part-of-Speech Tagging\n",
    "Part of speech tagging is the process of determining the category of word in accordance with its syntactic functions. So basically deciding wheter a word is a *noun*, *verb* etc.<br>In this notebook I will create simple LSTM model which will be able to determine wheter a word is a *noun*, *verb* or *adjective* in a given sentence.<br>\n",
    "\n",
    "#### Why do we even need that?\n",
    "It can be used in various ways but the most popular and useful are:\n",
    "- Determinig on what subject is someone talking about\n",
    "- Creating artificial sentences\n",
    "- Understanding the context of a sentence (example: We have **major** advantage VS **major** Ted, report for duty\n",
    "\n",
    "# Preparing the Data\n",
    "\"The data\" in that case will be 4 sentences I wrote, so very small dataset but for the sake of example it is perfect. Train set is a list of 4 tuples, where each tuple has a following structure: `([\"word1\", \"word2\", \"word3\", ...],[\"tag1\", \"tag2\", \"tag3\", ...])` and tags are `DET, NN and V`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'princess': 1, 'drunk': 2, 'that': 3, 'juice': 4, 'taylor': 5, 'admire': 6, 'kanye': 7, 'dog': 8, 'likes': 9, 'rope': 10, 'those': 11, 'cats': 12, 'eat': 13, 'garbage': 14}\n",
      "{'DET': 0, 'NN': 1, 'V': 2}\n"
     ]
    }
   ],
   "source": [
    "# create training data\n",
    "training_data = [\n",
    "    (\"The princess drunk that juice\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Taylor admire the Kanye\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"The dog likes that rope\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Those cats eat garbage\".lower().split(), [\"DET\", \"NN\", \"V\", \"NN\"])\n",
    "]\n",
    "\n",
    "# create dictionary of unique words\n",
    "word2idx = {}\n",
    "for words, tags in training_data:\n",
    "    for word in words:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "            \n",
    "# create dictionary for tags also\n",
    "tag2idx = {\"DET\" : 0, \"NN\" : 1, \"V\" : 2}\n",
    "\n",
    "print(word2idx)\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a helper function that converts list of words into torch tensor using previously defined `word2idx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 0, 7])\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(sequence, dictionary):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters:\n",
    "    sequence - list of words that will be mapped to torch tensor\n",
    "    dictionary - dict that maps words to indices\n",
    "    \n",
    "    \"\"\"\n",
    "    mappedwords = [dictionary[word] for word in sequence]\n",
    "    return torch.LongTensor(mappedwords)\n",
    "\n",
    "example = prepare_sequence(training_data[1][0], word2idx)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model\n",
    "\n",
    "Assumptions:\n",
    "- Input is a sequence of words so [\"word1\", \"word2\", \"word3\", ...]\n",
    "- All words are in the previously defined vocabulary: `word2idx`\n",
    "- We have 3 Tags: Noun(NN), Verb(V) and Determiner(DET)\n",
    "- The goal is to predict tag for each word\n",
    "\n",
    "But there is a problem with input size. Number of words in the sentence can vary so to address that problem we have to use *word embeddings*. Each word in our vocabulary will be presented as an vector of size `n`. Moreover each entry in a vector can be treated as a feature of the word, so due to that words(embedded vectors) can be compared using an angle between them as a measure of similarity (more about that [here](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html#word-embeddings-in-pytorch)).<br>\n",
    "\n",
    "Structure of LSTM<br>\n",
    "<img src=\"images/LSTM3.png\"><br>\n",
    "Credits: Udacity Computer vision Nanodegree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for tagging parts of speech\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        \"\"\"\n",
    "        Initialize layers of this model.\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # set dimension of hidden layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # first layer - embedding: turns words into vector of size embedding_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # second layer - LSTM takes embedded word vectors as input and outputs hidden states of size hidded_dim\n",
    "        # (in, out) = (embedding_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        \n",
    "        # third layer - linear layer that maps output of the LSTM to the number of tags we want\n",
    "        # (in, out) = (hidden_dim, tagse_size)\n",
    "        self.hidden2tags = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        self.hidden = self.init_hidden()\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Initialize hidden state of the model. At the begining of training we set this to 0's because we did not see anything before that.\n",
    "        \"\"\"\n",
    "        # dimensions here are (n_layers, batch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim), torch.zeros(1, 1, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        \"\"\"\n",
    "        Define the feedforward pass of the model\n",
    "        \"\"\"\n",
    "        # create embedded vectors for each word in a sentence\n",
    "        embedding = self.word_embeddings(sentence)\n",
    "        \n",
    "        # get the output an hidden state of the LSTMby applying it to embedded vectors\n",
    "        lstm_out, self.hidden = self.lstm(embedding.view(len(sentence), 1, -1), self.hidden)\n",
    "        \n",
    "        # get the scores for the most likely tag for a word\n",
    "        tag_outputs = self.hidden2tags(lstm_out.view(len(sentence),-1))\n",
    "        tag_scores = F.log_softmax(tag_outputs, dim=1)\n",
    "        \n",
    "        return tag_scores        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0880, -1.1530, -1.0572],\n",
      "        [-1.1327, -1.1362, -1.0305],\n",
      "        [-1.0290, -1.1485, -1.1223],\n",
      "        [-1.0473, -1.1636, -1.0884],\n",
      "        [-1.1103, -1.1488, -1.0398]], grad_fn=<LogSoftmaxBackward>) torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# define embedding dimension, here we have a simple example so we will keep it small\n",
    "# in more complex tasks those vectors grows to sizes like 64, 128 or even 256\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "# instantiate the model\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
    "\n",
    "# define loss function and optimizer\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# And now little test before training\n",
    "test_sentence = \"The dog drunk that juice\".lower().split()\n",
    "\n",
    "# first we need to prepare input sequence\n",
    "inputs = prepare_sequence(test_sentence,word2idx)\n",
    "\n",
    "tag_scores = model(inputs)\n",
    "# here we have torch tensor of size (5, 3) because fro each word we have 3 predictions regarding part of speech tag (DET, NN, V)\n",
    "print(tag_scores, tag_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train the model\n",
    "In epoch of the training loop each sentence will go through the LSTM model. For each sentence following actions will be taken:\n",
    "- zero the gradients\n",
    "- zero the hidden state of LSTM. WHY? because hidden state is for \"remembering\" words within the sentence in order to establish connections between them. Not zero-ing hidden state after each senetence would cause the end state from one sentence be an input to the first LSTM cell of the following sentence which would indicate connection between them which is not true in our case\n",
    "- Prepares our data for training: turn sentences into tensors\n",
    "- Runs a forward pass on our inputs to get tag_scores\n",
    "- Calculates the loss between tag_scores and the true tag\n",
    "- Updates the weights of our model using backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 0.96986\n",
      "Epoch: 40, loss: 0.79845\n",
      "Epoch: 60, loss: 0.55432\n",
      "Epoch: 80, loss: 0.31621\n",
      "Epoch: 100, loss: 0.17086\n",
      "Epoch: 120, loss: 0.10280\n",
      "Epoch: 140, loss: 0.06949\n",
      "Epoch: 160, loss: 0.05108\n",
      "Epoch: 180, loss: 0.03978\n",
      "Epoch: 200, loss: 0.03227\n",
      "Epoch: 220, loss: 0.02699\n",
      "Epoch: 240, loss: 0.02309\n",
      "Epoch: 260, loss: 0.02012\n",
      "Epoch: 280, loss: 0.01778\n",
      "Epoch: 300, loss: 0.01590\n",
      "Epoch: 320, loss: 0.01435\n",
      "Epoch: 340, loss: 0.01307\n",
      "Epoch: 360, loss: 0.01199\n",
      "Epoch: 380, loss: 0.01106\n",
      "Epoch: 400, loss: 0.01026\n",
      "Epoch: 420, loss: 0.00956\n",
      "Epoch: 440, loss: 0.00895\n",
      "Epoch: 460, loss: 0.00841\n",
      "Epoch: 480, loss: 0.00793\n",
      "Epoch: 500, loss: 0.00750\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In this exapmle we have only 4 sentences in outr train set so 300 epochs is not much \n",
    "n_epochs = 500\n",
    "epoch_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # get all sentences and corresponding tags in the training data\n",
    "    for sentence, tags in training_data:\n",
    "        \n",
    "        # zero the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # zero the hidden state of the LSTM, this detaches it from its history\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # prepare the inputs for processing by out network, \n",
    "        # turn all sentences and targets into Tensors of numerical indices\n",
    "        sentence_in = prepare_sequence(sentence, word2idx)\n",
    "        targets = prepare_sequence(tags, tag2idx)\n",
    "\n",
    "        # forward pass to get tag scores\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # compute the loss, and gradients \n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the model parameters with optimizer.step()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # add loss fro meach epoch to the lsit for printing purposes\n",
    "    epoch_list.append(epoch_loss/len(training_data))\n",
    "    # print out avg loss per 20 epochs\n",
    "    if(epoch%20 == 19):\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(training_data)))\n",
    "\n",
    "plt.plot(epoch_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can be seen that loss quickly converges. Now we can check again our test sentence `The dog drunk that juice`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'dog', 'drunk', 'that', 'juice'] ['DET', 'NN', 'V', 'DET', 'NN']\n"
     ]
    }
   ],
   "source": [
    "# test sentence again\n",
    "test_sentence = \"The dog drunk that juice\".lower().split()\n",
    "\n",
    "# covert sentence to the input format\n",
    "test_input = prepare_sequence(test_sentence, word2idx)\n",
    "\n",
    "# predicts tag scores\n",
    "tag_scores = model(test_input)\n",
    "\n",
    "# print the most likely tag for each word\n",
    "_, predicted_tags = torch.max(tag_scores, dim=1)\n",
    "# undo the tags mapping in order to display keys, not values\n",
    "final_output = [list(tag2idx.keys())[tag_score]for tag_score in predicted_tags.tolist()]\n",
    "print(test_sentence, final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our model perfectly predicted part of speech for each word in the test sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
